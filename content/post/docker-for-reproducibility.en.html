---
title: Docker for reproducibility
author: Jay Achar
date: '2020-02-16'
slug: docker-for-reproducibility
categories:
  - rstats
tags:
  - docker
  - research
description: 'Reproducible analyses using R with Docker'
images:
  - ''
linktitle: ''
---

<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<script src="/rmarkdown-libs/elevate-section-attrs/elevate-section-attrs.js"></script>


<p>In the last few weeks, I’ve been working with an analysis that I first started 3 years ago. The study
was accepted for an international conference in late 2019 and some of the questions that came
up from the audience rekindled my ambition of improving on the original analysis.</p>
<p>This study represented my first analysis performed solely with R after having learnt to use Stata
earlier in my research career. For that reason, I have a little nostalgia towards this particular piece,
but more importantly, it means the analysis wasn’t structured in a way that helps revitalisation!</p>
<p>When looking at the scripts, folders and raw data, it’s clear that while the analysis had structure,
it wasn’t intuitive when scanning with new eyes. The poor documentation added to the sense
that the work was designed for only one reader: myself in 2017.</p>
<p>So, this blog post represents some of the key lessons I’ve been schooled on as I’ve tried to get
this three year old analysis to run again.</p>
<p>Clone or fork <a href="https://www.github.com/JayAchar/reproduce-blogpost" target="_blank">this repo</a> if you
would like some sample code that I’ll refer to through this post.</p>
<div id="reproducibility-in-research" class="section level1">
<h1>Reproducibility in research</h1>
<p>The question of <em>‘Why do we need reproducibility in research?’</em> should be fairly obvious.
In my case, lack of knowledge was initially the barrier to addressing this, but soon enough I realised
that the process was much easier than I had thought.</p>
<p>My motivation for learning about some aspects of reproducibility in research and then moving on to
work with some of tools available, came from returning to analyses that I had run in the past.
As time goes on, I’m relooking at more and more historical analyses and recognising issues that
seem to crop up again and again. Where documentation and dependency management is well
organised, I’m able to quickly re-run, adjust or refactor an analysis to answer questions from colleagues
or reviewers.</p>
<p>Some of other aspects of reproducibility in statistical analyses that I won’t cover here include:</p>
<ol style="list-style-type: decimal">
<li>Version control,</li>
<li>Transparency in code development,</li>
<li>Relative paths in code,</li>
<li>Unit testing,</li>
<li>Continuous integration</li>
</ol>
<p>They all deserve their own consideration, so maybe something that I will return to in future posts.</p>
</div>
<div id="dependencies" class="section level1">
<h1>Dependencies</h1>
<p>One of the biggest challenges with revisiting code that worked in the past is the inevitable updating
of dependencies. <strong>Dependencies are additional resources that your code requires to run correctly</strong>. When
discussing R analyses, the most obvious examples are the packages of functions we regularly incorporate
into our interactive workflow. Think <a href="https://dplyr.tidyverse.org/"><code>dplyr</code></a>,
<a href="https://ggplot2.tidyverse.org/"><code>ggplot2</code></a>, <a href="https://cran.r-project.org/web/packages/car/index.html"><code>car</code></a>
and maybe <a href="https://cran.r-project.org/web/packages/rmarkdown/index.html"><code>rmarkdown</code></a>.</p>
<p>When dependencies are updated, functions may change their behaviour, require different arguments as inputs,
or stop existing altogether. This is especially true of packages that are still in development or where
authors are relatively new to package maintenance.</p>
<p>In software development, professional programmers manage this issue by working within a <strong><em>development
environment</em></strong> that defines exact versions of all dependencies.</p>
<p>One of the most popular tools, <a href="https://www.docker.com">docker</a>, is freely available for all, is able
to run on all operating systems, has numerous online resources to learn and debug problems and a
<a href="https://hub.docker.com">repository</a> of <em>images</em> which save users time and effort. There are other approaches
to tackle this problem in R including <a href="https://rstudio.github.io/packrat/"><code>packrat</code></a> and
<a href="https://rstudio.github.io/renv/articles/renv.html"><code>renv</code></a>.</p>
<p>I have preferred using docker for two reasons.
First, the code for managing dependencies with docker is very distinct from the analysis and R code itself.
I believe this allows for easier maintenance, updating and debugging. Second, the docker workflow can be
applied to more complex analyses which might use other programming languages. For example, in one of my
projects, I have used a PostgreSQL server for internal testing purposes. The obvious downside of docker is
that it requires installation of the docker software - something users with limtied rights on their computer
may not be able to undertake.</p>
</div>
<div id="building-a-docker-image" class="section level1">
<h1>Building a docker image</h1>
<p>Docker works using concepts of <strong><em>images</em></strong> and <strong><em>containers</em></strong>. I won’t go into details
here, but there are lots of resources, including the
<a href="https://docs.docker.com/engine/docker-overview/">official documentation</a>, to help understand
the way docker works. If you’re interested in developing your own custom images, then I would
recommend reading the documentation, blog posts and also YouTube videos relating to your exact use
csae.</p>
<p>Very briefly, a docker <strong>image</strong>:</p>
<ul>
<li>is <strong>built</strong> once from a template file,</li>
<li>incorporates all files relevant for the purpose of the image,</li>
<li>can be rebuilt when changes are required</li>
</ul>
<p>While, a docker <strong>container</strong>:</p>
<ul>
<li>runs an instance of image,</li>
<li>performs the tasks set out in the image build,</li>
<li>can be stopped and restarted to duplicate tasks</li>
</ul>
<p>So, when we build an <strong>image</strong>, we can define versions of the code and its dependencies so that
the results of running the <strong>container</strong> are predicatable and reproducable.</p>
<div id="dockerfile" class="section level2">
<h2>Dockerfile</h2>
<p>Within the folder containing your R project, create a file called <em>Dockerfile</em> - the spelling’s
important and there should be no file extension.</p>
<p>This is the template which will be <strong>built</strong> into our analysis image. The file is based on exact
syntax so be precise. This file can be be version controlled to ensure changes can be rolled back
if required.
Either in your command line editor, or other code editor start editing
the Dockerfile.</p>
<pre class="r"><code># versioned R distribution with tidyverse and Rstudio installed
FROM rocker/tidyverse:3.6.1</code></pre>
<p>Our analysis-specific image will add our specific needs on top of the
<a href="https://www.rocker-project.org/images/">rocker/tidyverse</a> image. Including the version tag
ensures that the image will be built with that version of R and that all installed packages
will be versioned to work with this R-version. The packages associated with this version of
R will be downloaded from MRAN, a Microsoft-maintaned repository that mirrors CRAN but includes
date labelled snapshots to allow users to specify exact version of packages they need.</p>
<p>Create an additional R-script within your project folder which will install all of the packages
requried by your analysis. The base image above includes all packages included in the <code>tidyverse</code>,
so no need to re-install them at this stage. This R-script should be similar to any other R code:</p>
<pre class="r"><code># install packages into analysis Docker image
install.packages(&quot;skimr&quot;)</code></pre>
<p>Then add the following lines to your Dockerfile to ensure this file is added to the docker image
along with all files from your analysis <code>R</code> folder.</p>
<pre class="r"><code># define additional packages to install
ADD ./packages.R /tmp/packages.R
# reduce typing by setting working directory
WORKDIR /home/rstudio_user
# add analysis scripts
ADD ./R ./R</code></pre>
<p>In the next few lines of the Dockerfile, we’ll create an analysis output folder and a data
folder before installing all of the packages we defined in the <code>packages.R</code> file. When the
container is started, these folders will be mapped to folders you define on your own computer.</p>
<pre class="r"><code># add output folder
RUN mkdir ./output \
# add raw data folder
 &amp;&amp; mkdir ./raw \
# install packages
 &amp;&amp; Rscript /tmp/packages.R </code></pre>
<p>Finally, the analysis in the example code is designed to be run without any user input. You can
see that the <code>analysis.R</code> script in the <code>R/</code> folder generates a <code>skimr</code> summary of the
mtcars data set then writes this to a .csv file in the <code>output</code> folder. In addition, a <code>ggplot2</code> graph
is generated using the diamonds data set and saved in the <code>output</code> folder. Since <code>ggplot2</code> is included
in the tidyverse group of packages incorporated into our base docker image, we do not need to install
it through our <code>packages.R</code> script.</p>
<p>To make the image run the analysis when a container is started, we use the following final line
in our Dockerfile:</p>
<pre class="r"><code># run analysis
CMD [&quot;Rscript&quot;, &quot;R/analysis.R&quot;]</code></pre>
</div>
<div id="build-image" class="section level2">
<h2>Build image</h2>
<p>The next step is to build the analysis image using the command below. This one needs to be entered
into your command line terminal - <code>terminal</code> on Mac OS X or <code>Command Prompt</code> on Windows.</p>
<pre class="r"><code># navigate to your analysis folder where your Dockerfile is saved
cd &lt;&lt;analysis-folder&gt;&gt;
# build the image using the docker engine
docker build -t reproducible-image .</code></pre>
<p>Don’t miss the full stop at the end of the build command - the command won’t work without it.</p>
<p>All being well, the docker engine will take some time to download and unpack the necessary
files then end with message confirming a successful build.</p>
<p>To check that your image has been built successfully, you can search all of the docker images
on your computer:</p>
<pre class="sh"><code># search for reproducible-image amongst all local docker images
docker images | grep &#39;reproducible-image&#39;</code></pre>
</div>
<div id="start-container" class="section level2">
<h2>Start container</h2>
<p>Now we have our image, it’s time to start a container:</p>
<pre class="r"><code># start container
docker run --rm -d --name reproducible-container \
        -v &lt;&lt;add_your_data_folder_path_here&gt;&gt;:/home/rstudio_user/raw \
        -v &lt;&lt;add_your_analysis_output_folder_here&gt;&gt;:/home/rstudio_user/output \
        -p 8787:8787 \
        reproducible-image</code></pre>
<p>This command will start a docker container using the image you have defined in your Dockerfile.
The final line of the <code>Dockerfile</code> will run your analysis script, after which the container will
stop automatically. The <code>--rm</code> flag within the <code>docker run</code> command tells docker to remove the
container immediately after it is stopped. The <code>-v</code> flags ensure that any output from the analysis
- a .csv and .png files in our example - are saved in the defined folder on your computer.</p>
<p>A slightly different approach is required where interactive execution of an analysis is required.
Since the <code>rocker/tidyverse</code> docker image includes a RStudio server instance, it’s actually quite
straightforward to set up. The <a href="https://hub.docker.com/r/rocker/tidyverse/"><code>rocker</code></a> online resources
are great for explaining how to implement this if required.</p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>This approach of packaging your R code into a docker image should ensure that your analysis is
both reproducible and transferable to other computers. The image I’ve described is very simple
and could be improved upon both in terms of functionality as well as size. However, the purpose
of this post was to describe a simple workflow to encourage you to incorporate this final
step into your analysis process.</p>
<p>Let me know if you have suggestions for improving the docker image and do try out the example code in
the <a href="https://github.com/JayAchar/reproduce-blogpost">Github repo</a>.</p>
</div>
